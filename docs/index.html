<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We compare counterfactual image generation methods on a variety of datasets and metrics">
  <meta property="og:title" content="Benchmarking Counterfactual Image Generation"/>
  <meta property="og:description" content="We compare counterfactual image generation methods on a variety of datasets and metrics"/>
  <meta property="og:url" content="https://gulnazaki.github.io/counterfactual-benchmark/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Benchmarking Counterfactual Image Generation">
  <meta name="twitter:description" content="We compare counterfactual image generation methods on a variety of datasets and metrics">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="benchmark, benchmarking, causal, counterfactual, HVAE, VAE, GAN, composition, effectiveness, realism, minimality, counterfactual image generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Benchmarking Counterfactual Image Generation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/carousel.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Benchmarking Counterfactual Image Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://vios.science/team/thomas" target="_blank">Thomas Melistas</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/nikosspyrou" target="_blank">Nikos Spyrou</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/nefeli" target="_blank">Nefeli Gkouti</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/sanchez" target="_blank">Pedro Sanchez</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://thanosvlo.github.io/" target="_blank"> Athanasios
                  Vlontzos</a><sup>4, 6</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.co.uk/citations?user=z1bkjU8AAAAJ" target="_blank"> Yannis Panagakis</a><sup>1, 2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=VPsjPNUAAAAJ" target="_blank">Giorgos Papanastasiou<sup>2, 5</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/tsaftaris" target="_blank">Sotirios A. Tsaftaris<sup>2, 3</sup></a>
              </span>

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>National & Kapodistrian University of Athens, Greece,
                      <sup>2</sup>Archimedes/Athena RC, Greece<br>
                      <sup>3</sup>The University of Edinburgh, UK,
                      <sup>4</sup>Imperial College London, UK<br>
                      <sup>5</sup>The University of Essex, UK,
                      <sup>6</sup>Spotify<br>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2403.20287.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/gulnazaki/counterfactual-benchmark" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2403.20287" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video--
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
      </h2>
    </div>
  </div>
</section>
End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generative AI has revolutionised visual content editing, empowering users to effortlessly modify images and videos. However, not all edits are equal. To perform
            realistic edits in domains such as natural image or medical imaging, modifications
            must respect causal relationships inherent to the data generation process. Such
            image editing falls into the counterfactual image generation regime. Evaluating
            counterfactual image generation is substantially complex: not only it lacks observable ground truths, but also requires adherence to causal constraints. Although
            several counterfactual image generation methods and evaluation metrics exist, a
            comprehensive comparison within a unified setting is lacking. We present a comparison framework to thoroughly benchmark counterfactual image generation methods.
            We integrate all models that have been used for the task at hand and expand them
            to novel datasets and causal graphs, demonstrating the superiority of Hierarchical VAEs across most datasets and metrics. Our framework is implemented in a
            user-friendly Python package that can be extended to incorporate additional SCMs,
            causal methods, generative models, and datasets for the community to build on.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered"">Exploring What-Ifs: The Future of Counterfactual Image Generation</h2>
            <p>
                Counterfactual image generation is an exciting frontier in generative AI that creates plausible alternative versions of images to explore "what if" scenarios. nlike traditional image editing, which often alters images without considering the underlying causal relationships, counterfactual image generation maintains these essential connections to produce realistic and coherent results.
            </p>
            <p>
                Counterfactuals allow us to visualize potential consequences of changing specific attributes, such as age or gender, within an image. For instance, modifying a person's age might lead to an unrealistic outcome if not informed by causal relationships. By addressing these nuances, counterfactual image generation aims to ensure that the edited images reflect plausible realities rather than misleading artifacts.
            </p>
            <p>
                This benchmark is crucial as evaluating counterfactual images presents unique challenges, lacking observable ground truths and requiring a balance between realism and causal adherence. Although various methods have been proposed for this task, fairly comparing them is challenging because they utilize different datasets, evaluation metrics, and experimental setups. Our research introduces a comprehensive framework using Structural Causal Models (SCM) to guide generative models through these complexities.
            </p>
            <img src="static/images/motivation.png" class="blend-img-background smaller-image" alt="Figure 1: (a) A plausible causal graph for human faces; (b) Factual images (no intervention); (c) Causal counterfactual images using the graph of (a) to perform the interventions do(Female) (upper panel) and do(Young) (lower panel); (d) Non-causal image editing.">
            <figcaption>Figure 1: (a) A plausible causal graph for human faces; (b) Factual images (no intervention); (c) Causal counterfactual images using the graph of (a) to perform the interventions <em>do(Female)</em> (upper panel) and <em>do(Young)</em> (lower panel); (d) Non-causal image editing.</figcaption>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered"">Key Contributions</h2>
            <ol>
              <li>We introduce a comprehensive framework to evaluate image generation models within the Deep-SCM paradigm across various datasets, including synthetic, natural, and medical images.</li>
              <li>We expand existing models to handle previously untested datasets and causal graphs, specifically testing HVAE and GAN for human faces and creating a GAN for counterfactual brain MRIs.</li>
              <li>We benchmark these models extensively using multiple metrics for assessing causal SCM-based counterfactual image generation.</li>
              <li>We offer a user-friendly Python package to facilitate the evaluation of new causal mechanisms and datasets.</li>
            </ol>
            <br>
            <p>
              This work aspires to be the go-to resource for researchers and developers, paving the way for future advancements in counterfactual image generation.
            </p>
        </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">How are counterfactuals obtained?</h2>
            <p>Counterfactuals are derived using Structural Causal Models (SCMs). An SCM consists of mechanisms that outline how variables relate to one another and noise distributions that account for unobservable factors. By employing a directed acyclic graph (DAG), we can recursively calculate relationships among variables, which are referred to as endogenous, while noise variables are treated as exogenous. This structured approach allows us to predict the effects of interventions on specific variables through a defined process.
            </p>

            <p>To obtain counterfactuals, we utilize the Abduction-Action-Prediction paradigm. This involves three key steps: Abduction, where we infer the noise compatible with an observation; Action, where we alter the structural equations to reflect our intervention; and Prediction, where we compute the resulting outcomes based on the modified model. Following previous work, we incorporate Conditional Normalizing Flows for the mechanisms of the image attributes, while for the image mechanisms we condider (i) Conditional Variational Autoencoders (VAEs), (ii) Conditional Hierarchical VAEs (HVAEs) and (iii) Conditional Generative Adversarial Networks (GANs).
            </p>

            <br>
            <img src="static/images/abduction_action_prediction.png" class="blend-img-background center-image" alt="Figure 2: Producing a counterfactual MorphoMNIST digit: Abduction: We infer the exogenous noise separately, using Normalising Flows f −1 for the attributes and the encoder of the image mechanism (e.g. VAE, HVAE or GAN), conditioned on factual parents. Action: We intervene (do(t ∗ )) only on thickness. Prediction: We employ the Normalizing Flow f conditioned on the counterfactual thickness t ∗ to obtain i ∗ after the intervention. Note that this is not needed for t ∗ on which we intervene and for d ∗ that has no parents in the DAG. Finally, the decoder generates the counterfactual image, given the exogenous noise U img and all counterfactual attributes.">
            <figcaption> Figure 2: Producing a counterfactual MorphoMNIST digit:
              <strong><em>Abduction</em>:</strong> We infer the exogenous noise separately, using Normalising Flows <em>f<sup>-1</sup></em> for the attributes and the encoder of the image mechanism (e.g. VAE, HVAE, or GAN), conditioned on factual parents.
    <strong><em>Action</em>:</strong> We intervene (<em>do(t<sup>*</sup>)</em>) only on <em>thickness</em>.
    <strong><em>Prediction</em>:</strong> We employ the Normalizing Flow <em>f</em> conditioned on the counterfactual thickness <em>t<sup>*</sup></em> to obtain <em>i<sup>*</sup></em> after the intervention. Note that this is not needed for <em>t<sup>*</sup></em> on which we intervene and for <em>d<sup>*</sup></em> that has no parents in the DAG. Finally, the decoder generates the counterfactual image, given the exogenous noise <em>U<sub>img</sub></em> and all counterfactual attributes.</figcaption>          </div>
    <br><br>
    <p>During counterfactual inference, we independently infer the noise for each variable while ensuring that any intervened variables are set to constants. For example, when generating a counterfactual digit in the MorphoMNIST dataset, we infer the necessary noise for attributes and images, make specific changes to a feature (like thickness), and then predict the new image based on these adjustments. This method highlights the importance of causal reasoning in generating realistic counterfactual images and provides a framework for exploring how changes in attributes can lead to different visual outcomes.
    </p>
  </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">Key Metrics</h2>
    <ul>
        <li><strong>Composition</strong>: Ensures the image remains unchanged under "null-intervention" (when no change is applied). We use distances like the <em>L1 distance</em> and <em>LPIPS</em> to measure this.</li>
        <li><strong>Effectiveness</strong>: Confirms the intervention worked as intended. We use predictors on image features and metrics like <em>accuracy</em> and <em>F1-score</em> for evaluation.</li>
        <li><strong>Realism</strong>: Measures how similar the counterfactual is to real images, using the <em>Fréchet Inception Distance (FID)</em>.</li>
        <li><strong>Minimality</strong>: Ensures changes are focused on the intended attribute, measured with <em>Counterfactual Latent Divergence (CLD)</em> for closeness to the original.</li>
    </ul>

    <p>In essence, evaluating counterfactual images requires balancing these metrics to ensure images are realistic, minimal in changes, and effective in showcasing intended modifications.</p>
  </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">Results</h2>
            <p>Given the availability of architectures and demonstrated outcomes in the literature, we benchmark the above three models on the following datasets:</p>
            <ol>
                <li><a href="https://github.com/dccastro/Morpho-MNIST" target="_blank">MorphoMNIST</a></li>
                <li><a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank">CelebA</a> (simple & complex causal graph)</li>
                <li><a href="https://adni.loni.usc.edu/data-samples/adni-data/neuroimaging/mri/" target="_blank">ADNI</a></li>
            </ol>
            <img src="static/images/causal_graphs.png" class="blend-img-background smaller-image" alt="Figure 3: Causal graphs for all examined datasets.">
            <figcaption>Figure 3: Causal graphs for all examined datasets.</figcaption>

            <br>
          <h2 class="title is-5 has-text-centered">Composition</h2>
          <p>Our findings indicate that HVAE consistently outperforms other models on <strong>composition</strong>. While both VAE and GAN show similar performance, they have distinct drawbacks: VAE reconstructions maintain image structure but appear too blurry, while GAN alters image structure, especially with complex datasets.</p>

          <p>The advantage of HVAE over other models becomes clear as data complexity increases (e.g., with datasets like CelebA and ADNI). This improvement may be attributed to HVAE's multiple stochastic layers of latent variables, which allow it to more effectively learn and retain the prior of the latent from the data distribution across composition cycles.</p>

          <img src="static/images/composition.png" class="blend-img-background smaller-image" alt="Figure 4: Qualitative evaluation of composition across all datasets/graphs. From left to right across
          all datasets: (i) factual, (ii) null-intervention (reconstruction) (iii) 10 cycles of null-intervention">
            <figcaption>Figure 4: Qualitative evaluation of composition across all datasets/graphs. From left to right across all datasets: <br>(i) factual, (ii) null-intervention (reconstruction) (iii) 10 cycles of null-intervention</figcaption>

          <br>
          <h2 class="title is-5 has-text-centered">Effectiveness</h2>
          <p>We attribute HVAE’s superior performance in generating counterfactuals to the high expressivity of its hierarchical latent variables. This hierarchical structure enables HVAE to align closely with the underlying causal graph, allowing it to retain the semantic information of the original image while implementing the intended causal modifications effectively.</p>

    <p>The rich representation of latent variables in HVAE not only preserves the original content but also allows for more accurate and nuanced manipulation of causal factors. This results in counterfactuals that are both effective and plausible, making HVAE a powerful tool for counterfactual generation.</p>
    <img src="static/images/effectiveness.png" class="blend-img-background smaller-image" alt="Figure 5: Qualitative evaluation of effectiveness for all datasets/graphs. From left to right across
    datasets: the leftmost image is the factual one and then each column shows the causal counterfactual
    image after intervening on a single attribute. v: volume; vent: ventricle; eg: eyeglasses.">
      <figcaption>Figure 5: Qualitative evaluation of effectiveness for all datasets/graphs. From left to right across datasets: the leftmost image is the factual one and then each column shows the causal counterfactual image after intervening on a single attribute.<br>v: volume; vent: ventricle; eg: eyeglasses.</figcaption>

      <br>
      <h2 class="title is-5 has-text-centered">Realism & Minimality</h2>
      <p>We found that HVAE generates the most realistic counterfactuals across most metrics and datasets, namely the ones closest to the original data distribution. Introducing more attributes to condition the HVAE (complex graph on CelebA) affected image realism, while GAN maintained good performance. The GAN model, while capable of generating realistic images, failed to achieve optimal minimality due to its lower ability to preserve factual details, compared to HVAE, which is also evident by the composition metric.</p>

          </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">🎉 Summing it up! 🎉</h2>
            <p>Our work bridges a critical gap in counterfactual image generation by introducing a unified framework that rigorously benchmarks diverse models, datasets, and causal graphs. With this standardized evaluation, we uncover the exceptional expressivity of hierarchical structures in HVAE, which outperforms VAEs and GANs by capturing causal variables more accurately and preserving semantic details. Notably, our experiments with complex datasets—like human faces and brain MRIs—highlight HVAE’s capacity to generate realistic, causally sound counterfactuals. As we extend the reach of this benchmark, we look forward to seeing the community build on our foundation, exploring new methods, models, and causal graphs. To support these efforts, we’ve created an easy-to-use Python package that enables future innovations in counterfactual generation.</p>
  </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<br>

<div class="columns is-centered has-text-centered">
  <h2 class="title is-3">Generated Counterfactual Samples for all Datasets</h2>
</div>

<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-5">MorphoMNIST</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel" data-directory="static/images/morphomnist">
        <!-- Carousel items will be dynamically added here by JavaScript -->
      </div>
      <h2 class="subtitle has-text-centered">(from top to bottom: VAE, HVAE, GAN)</h2>
    </div>
  </div>
</section>

<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-5">CelebA (simple)</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel" data-directory="static/images/simple">
        <!-- Carousel items will be dynamically added here by JavaScript -->
      </div>
      <h2 class="subtitle has-text-centered">(from top to bottom: VAE, HVAE, GAN)</h2>
    </div>
  </div>
</section>

<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-5">CelebA (complex)</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel" data-directory="static/images/complex">
        <!-- Carousel items will be dynamically added here by JavaScript -->
      </div>
      <h2 class="subtitle has-text-centered">(from top to bottom: VAE, HVAE, GAN)</h2>
    </div>
  </div>
</section>


<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-5">ADNI</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel" data-directory="static/images/adni">
        <!-- Carousel items will be dynamically added here by JavaScript -->
      </div>
      <h2 class="subtitle has-text-centered">(from top to bottom: VAE, HVAE, GAN)</h2>
    </div>
  </div>
</section>


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
         Your image here
        <img src="static/images/composition.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Composition
        </h2>
      </div>
      <div class="item">
         Your image here
        <img src="static/images/effectiveness.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Effectiveness
       </h2>
     </div>
  </div>
</div>
</div>
</section> -->
 <!-- End image carousel -->




<!-- Youtube video
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
End youtube video -->


<!-- Video carousel
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
             Your video file here
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
End video carousel -->






<!-- Paper poster
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>

      </div>
    </div>
  </section>
End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>If you find this work helpful in your research, cite:
        @misc{melistas2024benchmarking,
              title={Benchmarking Counterfactual Image Generation},
              author={Thomas Melistas and Nikos Spyrou and Nefeli Gkouti and Pedro Sanchez and Athanasios Vlontzos and Yannis Panagakis and Giorgos Papanastasiou and Sotirios A. Tsaftaris},
              year={2024},
              eprint={2403.20287},
              archivePrefix={arXiv},
              primaryClass={cs.CV}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
