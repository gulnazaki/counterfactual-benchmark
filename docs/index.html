<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We compare counterfactual image generation methods on a variety of datasets and metrics">
  <meta property="og:title" content="Benchmarking Counterfactual Image Generation"/>
  <meta property="og:description" content="We compare counterfactual image generation methods on a variety of datasets and metrics"/>
  <meta property="og:url" content="https://gulnazaki.github.io/counterfactual-benchmark/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Benchmarking Counterfactual Image Generation">
  <meta name="twitter:description" content="We compare counterfactual image generation methods on a variety of datasets and metrics">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="benchmark, benchmarking, causal, counterfactual, HVAE, VAE, GAN, composition, effectiveness, realism, minimality, counterfactual image generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Benchmarking Counterfactual Image Generation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/carousel.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Benchmarking Counterfactual Image Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://vios.science/team/thomas" target="_blank">Thomas Melistas</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/nikosspyrou" target="_blank">Nikos Spyrou</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/nefeli" target="_blank">Nefeli Gkouti</a><sup>*1, 2, 3</sup>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/sanchez" target="_blank">Pedro Sanchez</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://thanosvlo.github.io/" target="_blank"> Athanasios
                  Vlontzos</a><sup>4, 6</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.co.uk/citations?user=z1bkjU8AAAAJ" target="_blank"> Yannis Panagakis</a><sup>1, 2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=VPsjPNUAAAAJ" target="_blank">Giorgos Papanastasiou<sup>2, 5</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://vios.science/team/tsaftaris" target="_blank">Sotirios A. Tsaftaris<sup>2, 3</sup></a>
              </span>

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>National & Kapodistrian University of Athens, Greece,
                      <sup>2</sup>Archimedes/Athena RC, Greece<br>
                      <sup>3</sup>The University of Edinburgh, UK,
                      <sup>4</sup>Imperial College London, UK<br>
                      <sup>5</sup>The University of Essex, UK,
                      <sup>6</sup>Spotify<br>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2403.20287.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- NeurIPS page link -->
                    <span class="link-block">
                      <a href="https://neurips.cc/virtual/2024/poster/97876" target="_blank"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <img src="static/images/NeurIPS-logo.svg" alt="NeurIPS Logo"/>
                        </span>
                        <span>NeurIPS 2024</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/gulnazaki/counterfactual-benchmark" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2403.20287" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Poster -->
              <span class="link-block">
                <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202024/97876.png" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-image"></i>
                </span>
                <span>Poster</span>
              </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video--
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
      </h2>
    </div>
  </div>
</section>
End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generative AI has revolutionised visual content editing, empowering users to effortlessly modify images and videos. However, not all edits are equal. To perform
            realistic edits in domains such as natural image or medical imaging, modifications
            must respect causal relationships inherent to the data generation process. Such
            image editing falls into the counterfactual image generation regime. Evaluating
            counterfactual image generation is substantially complex: not only it lacks observable ground truths, but also requires adherence to causal constraints. Although
            several counterfactual image generation methods and evaluation metrics exist, a
            comprehensive comparison within a unified setting is lacking. We present a comparison framework to thoroughly benchmark counterfactual image generation methods.
            We integrate all models that have been used for the task at hand and expand them
            to novel datasets and causal graphs, demonstrating the superiority of Hierarchical VAEs across most datasets and metrics. Our framework is implemented in a
            user-friendly Python package that can be extended to incorporate additional SCMs,
            causal methods, generative models, and datasets for the community to build on.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-3 has-text-centered"">What is Counterfactual Image Generation?</h2>
            <p>
                Counterfactual image generation is an exciting frontier in generative AI that creates plausible alternative versions of images to explore <em>"what if"</em> scenarios. Unlike traditional image editing, which often alters images without considering the underlying causal relationships, it explicitly models these essential connections to produce realistic and coherent results.
            </p>
            <p>
                Counterfactuals allow us to visualize potential consequences of changing specific attributes, such as age or gender, within an image. For instance, modifying a person's age might lead to an unrealistic outcome if not informed by causal relationships. By addressing these nuances, counterfactual image generation aims to ensure that the edited images reflect plausible realities rather than misleading artifacts.
            </p>
            <img src="static/images/motivation.png" class="blend-img-background smaller-image" alt="Figure 1: (a) A plausible causal graph for human faces; (b) Factual images (no intervention); (c) Causal counterfactual images using the graph of (a) to perform the interventions do(Female) (upper panel) and do(Young) (lower panel); (d) Non-causal image editing.">
            <figcaption>Figure 1: (a) A plausible causal graph for human faces; (b) Factual images (no intervention); (c) Causal counterfactual images using the graph of (a) to perform the interventions <em>do(Female)</em> (upper panel) and <em>do(Young)</em> (lower panel); (d) Non-causal image editing.</figcaption>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <!-- <div class="content"> -->
          <div class="level-set has-text-justified">

<h1 style="margin-bottom: 2px;">Generate Counterfactuals</h1>
<h1 class="title is-4" style="margin-top: 2px;">using the models we benchmark</h1>


<!-- Dataset Selector -->
<section>
  <label for="datasetSelector">Choose a dataset:</label>
  <select id="datasetSelector">
    <option value="MorphoMNIST" selected>MorphoMNIST</option>
    <option value="CelebA_simple">CelebA (simple)</option>
    <option value="CelebA_complex">CelebA (complex)</option>
    <option value="ADNI">ADNI</option>
  </select>

<!-- Dataset Preview Image -->
<div id="datasetPreviewContainer">
  <img id="datasetPreview" src="" alt="Dataset Preview">
</div>
</section>

<!-- Action Selector -->
<section id="actionSection">
  <label for="actionSelector">Intervene on:</label>
  <select id="actionSelector"></select>
</section>

<!-- Images Display -->

<section id="imagesSection" class="images-container">
  <figure class="image-item">
    <img id="factualImage" src="" alt="Factual Image" />
    <figcaption>Factual</figcaption>
  </figure>
  <figure class="image-item">
    <img id="vaeImage" src="" alt="VAE Image" />
    <figcaption>VAE</figcaption>
  </figure>
  <figure class="image-item">
    <img id="hvaeImage" src="" alt="HVAE Image" />
    <figcaption>HVAE</figcaption>
  </figure>
  <figure class="image-item">
    <img id="ganImage" src="" alt="GAN Image" />
    <figcaption>GAN</figcaption>
  </figure>
</section>

<!-- Try Another Sample Button -->
<section id="sampleButtonSection" style="text-align: center; margin-top: 20px;">
  <button id="tryAnotherSampleButton" class="button is-primary">Try Another Sample</button>
</section>

<script src="static/js/demo.js"></script>

</div>
</div>
</div>
</div>
</div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">

            <!-- <p>
              Evaluating counterfactual images presents unique challenges, lacking observable ground truths and requiring a balance between realism and causal adherence. Although various methods have been proposed for this task, fairly comparing them is challenging because they utilize different datasets, evaluation metrics, and experimental setups.
          </p> -->
            <h2 class="title is-4 has-text-centered">Key Contributions</h2>
            <ol>
              <li>We introduce a comprehensive framework to evaluate image generation models within the Deep-SCM paradigm across various datasets, including synthetic, natural, and medical images.</li>
              <li>We expand existing models to handle previously untested datasets and causal graphs, specifically testing HVAE and GAN on a non-trivial causal graph for human faces and devising a GAN architecture that generates counterfactual brain MRIs given multiple variables.</li>
              <li>We extensively benchmark these models adopting multiple metrics for assessing causal SCM-based counterfactual image generation.</li>
              <li>We offer a user-friendly Python package to accommodate and evaluate forthcoming causal mechanisms, datasets and causal graphs.</li>
            </ol>
            <br>
            <p>
              This work aspires to be the go-to resource for researchers and developers, paving the way for future advancements in counterfactual image generation.
            </p>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">How are counterfactuals obtained?</h2>
            <!-- <p>Counterfactuals are derived using Structural Causal Models (SCMs).
              An SCM consists of mechanisms that outline how variables relate to one another and noise distributions that account for unobservable factors.
              By employing a directed acyclic graph (DAG), we can recursively calculate relationships among variables,
              which are referred to as endogenous, while noise variables are treated as exogenous.
              This structured approach allows us to predict the effects of interventions on specific variables through a defined process.
            </p> -->

            <p>To obtain counterfactuals, we utilize the <strong><em>Abduction-Action-Prediction</em></strong> paradigm.
              This involves three key steps: <strong><em>Abduction</em></strong>, where we infer the noise compatible with an observation;
                <strong><em>Action</em></strong>, where we alter the structural equations to reflect our intervention; and <strong><em>Prediction</em></strong>, where we compute the resulting outcomes
              based on the modified model. Following previous work, we incorporate <strong>Conditional Normalizing Flows</strong> for the mechanisms of the attributes,
              while for the image mechanisms we consider (i) <strong>Conditional Variational Autoencoders (VAEs)</strong>, (ii) <strong>Conditional Hierarchical VAEs (HVAEs)</strong>
              and (iii) <strong>Conditional Generative Adversarial Networks (GANs)</strong>.
            </p>

            <br>
            <img src="static/images/abduction_action_prediction.png" class="blend-img-background center-image" alt="Figure 2: Producing a counterfactual MorphoMNIST digit: Abduction: We infer the exogenous noise separately, using Normalising Flows f −1 for the attributes and the encoder of the image mechanism (e.g. VAE, HVAE or GAN), conditioned on the factual parents. Action: We intervene do(t ∗ ) only on thickness. Prediction: We employ the Normalizing Flow f conditioned on the counterfactual thickness t ∗ to obtain i ∗ after the intervention. Note that this is not needed for t ∗ on which we intervene and for d ∗ that has no parents in the DAG. Finally, the decoder generates the counterfactual image, given the exogenous noise U img and all counterfactual attributes.">
            <figcaption> Figure 2: Producing a counterfactual MorphoMNIST digit:
              <strong><em>Abduction:</em></strong> We infer the exogenous noise separately, using Normalising Flows <em>f<sup>-1</sup></em> for the attributes and the encoder of the image mechanism (e.g. VAE, HVAE, or GAN), conditioned on the factual parents.
    <strong><em>Action:</em></strong> We intervene <em>do(t<sup>*</sup>)</em> only on <em>thickness</em>.
    <strong><em>Prediction:</em></strong> We employ the Normalizing Flow <em>f</em> conditioned on the counterfactual thickness <em>t<sup>*</sup></em> to obtain <em>i<sup>*</sup></em> after the intervention. Note that this is not needed for <em>t<sup>*</sup></em> on which we intervene and for <em>d<sup>*</sup></em> that has no parents in the DAG. <br>Finally, the decoder generates the counterfactual image, given the exogenous noise <em>U<sub>img</sub></em> and all counterfactual attributes.</figcaption>          </div>
    <!-- <br><br>
    <p>During counterfactual inference, we independently infer the noise for each variable while ensuring that any intervened variables are set to constants. For example, when generating a counterfactual digit in the MorphoMNIST dataset, we infer the necessary noise for attributes and images, make specific changes to a feature (like thickness), and then predict the new image based on these adjustments. This method highlights the importance of causal reasoning in generating realistic counterfactual images and provides a framework for exploring how changes in attributes can lead to different visual outcomes.
    </p> -->
  </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">Key Metrics</h2>
    <ul>
        <li><strong>Composition</strong>: Ensures the image remains unchanged under "null-intervention" (when no change is applied). We use distances like the <em>L1 distance</em> and <em>LPIPS</em> to measure this.</li>
        <img src="static/images/composition.svg" class="blend-img-background smaller-image" alt="Composition"><figcaption>Composition</figcaption>
        <br>
        <li><strong>Effectiveness</strong>: Confirms the intervention worked as intended. We use predictors on image features and metrics like <em>accuracy</em> and <em>F1-score</em> for evaluation.</li>
        <img src="static/images/effectiveness.svg" class="blend-img-background smaller-image" alt="Effectiveness"><figcaption>Effectiveness</figcaption>
        <br>
        <li><strong>Realism</strong>: Measures how similar the counterfactual is to real images, using the <em>Fréchet Inception Distance (FID)</em>.</li>
        <img src="static/images/realism.svg" class="blend-img-background smaller-image" alt="Realism"><figcaption>Realism</figcaption>
        <br>
        <li><strong>Minimality</strong>: Ensures changes are focused on the intended attribute, measured with <em>Counterfactual Latent Divergence (CLD)</em> for closeness to the original.</li>
        <img src="static/images/minimality.svg" class="blend-img-background smaller-image" alt="Minimality"><figcaption>Minimality</figcaption>
    </ul>
    <br>
    <p>In essence, evaluating counterfactual images requires balancing these metrics to ensure images are realistic, minimal in changes, and effective in showcasing intended modifications.</p>
  </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered"><em>Who is the winner?</em></h2>
            <img src="static/images/summary_table.svg" class="blend-img-background smaller-image" alt="Summary table showing the best performing models on each metric for all datasets">
            <figcaption>Summary table showing the best performing models on each metric for all datasets</figcaption>
            <br>
            <!-- <h2 class="title is-5 has-text-centered">Composition</h2> -->
          <p>Our findings indicate that HVAE consistently outperforms all other models on <strong>composition</strong>.
            VAE and GAN have distinct drawbacks: VAE reconstructions maintain image structure but appear too blurry, while GAN alters image structure, especially on complex datasets.
            The advantage of HVAE over other models becomes clear as data complexity increases (e.g. CelebA, ADNI).
            This improvement may be attributed to HVAE's multiple stochastic layers of latent variables, which allow it to more effectively learn and retain the prior of the latent from the data distribution.</p>

          <!-- <img src="static/images/composition.png" class="blend-img-background smaller-image" alt="Figure 4: Qualitative evaluation of composition across all datasets/graphs. From left to right across
          all datasets: (i) factual, (ii) null-intervention (reconstruction) (iii) 10 cycles of null-intervention">
            <figcaption>Figure 4: Qualitative evaluation of composition across all datasets/graphs. From left to right across all datasets: <br>(i) factual, (ii) null-intervention (reconstruction) (iii) 10 cycles of null-intervention</figcaption> -->
          <!-- <h2 class="title is-5 has-text-centered">Effectiveness</h2> -->
          <p>When measuring <strong>effectiveness</strong>, HVAE has the best score on most attributes, with VAE and GAN being competitive on other attributes, depending on the dataset.
            We believe that HVAE's hierarchical structure enables it to align closely with the underlying causal graph, allowing of a more accurate and nuanced manipulation of causal factors.
            This resulting in counterfactuals that are both effective and plausible.</p>
<!--
    <p>The rich representation of latent variables in HVAE not only preserves the original content but also allows for more accurate and nuanced manipulation of causal factors.
      This results in counterfactuals that are both effective and plausible, making HVAE a powerful tool for counterfactual generation.</p> -->
    <!-- <img src="static/images/effectiveness.png" class="blend-img-background smaller-image" alt="Figure 5: Qualitative evaluation of effectiveness for all datasets/graphs. From left to right across
    datasets: the leftmost image is the factual one and then each column shows the causal counterfactual
    image after intervening on a single attribute. v: volume; vent: ventricle; eg: eyeglasses.">
      <figcaption>Figure 5: Qualitative evaluation of effectiveness for all datasets/graphs. From left to right across datasets: the leftmost image is the factual one and then each column shows the causal counterfactual image after intervening on a single attribute.<br>v: volume; vent: ventricle; eg: eyeglasses.</figcaption> -->
      <!-- <h2 class="title is-5 has-text-centered">Realism & Minimality</h2> -->
      <p>We found that HVAE generates the most <strong>realistic</strong> counterfactuals across most metrics and datasets.
        However, introducing more attributes to condition the HVAE (as in CelebA (complex)) affected image realism, exhibiting a known issue of its counterfactual training step, termed <em>attribute amplification</em>.
        GANs, while capable of generating realistic images, fail to achieve optimal <strong>minimality</strong> by preserving factual details, which is also evident through the composition metric.</p>

          </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-small colorful-section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <h2 class="title is-4 has-text-centered">🎉 Summing it up! 🎉</h2>
            <p>Our work bridges a critical gap in counterfactual image generation by introducing a unified framework that rigorously benchmarks diverse models, datasets, and causal graphs. With this standardized evaluation, we uncover the exceptional expressivity of hierarchical structures in HVAE, which outperforms VAEs and GANs by capturing causal variables more accurately and preserving semantic details. Notably, our experiments with complex datasets—like human faces and brain MRIs—highlight HVAE’s capacity to generate realistic, causally sound counterfactuals. As we extend the reach of this benchmark, we look forward to seeing the community build on our foundation, exploring new methods, models, and causal graphs. To support these efforts, we publish our open-source codebase to enable future contributions in counterfactual image generation.</p>
  </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Youtube video
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
End youtube video -->


<!-- Video carousel
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
             Your video file here
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
End video carousel -->

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <img src="static/images/poster.png" width="100%" height="550">
          </img>
      </div>
    </div>
  </section> -->
<!-- End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>If you find this work helpful in your research, cite:
        @inproceedings{
          melistas2024benchmarking,
          title={Benchmarking Counterfactual Image Generation},
          author={Thomas Melistas and Nikos Spyrou and Nefeli Gkouti and Pedro Sanchez and Athanasios Vlontzos and Yannis Panagakis and Giorgos Papanastasiou and Sotirios A. Tsaftaris},
          booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
          year={2024},
          url={https://openreview.net/forum?id=0T8xRFrScB}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
